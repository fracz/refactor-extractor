commit a1786a1bb0dc25d97ac5f47d1115253a031394ce
Author: Dmitry Jemerov <yole@jetbrains.com>
Date:   Wed Oct 12 16:13:35 2011 +0200

    spellchecker refactoring: Tokenizer.split() no longer creates huge amount of temp objects